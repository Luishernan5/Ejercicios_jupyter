{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f75b1b",
   "metadata": {},
   "source": [
    "# Regresión Logística: Detección de SPAM\n",
    "\n",
    "En este ejercicio se muestran los fundamentos de la Regresión Logística planteando uno de los primeros problemas que fueron solucionados mediante el uso de técnicas de Machine Learning: Detección de SPAM.\n",
    "\n",
    "## Enunciado del Ejercicio\n",
    "\n",
    "Se Propone la construcción de un sistema de aprendizaje automático capaz de predicir si un correo determinado corresponde a un correo SPAm o no, para esto, se utilizara el siguiente DataSet.\n",
    "[DataSet](https://www.kaggle.com/datasets/imdeepmind/preprocessed-trec-2007-public-corpus-dataset)\n",
    "\n",
    "The corpus trec07p contains 75, 419 messages:\n",
    "\n",
    "25,220 Ham\n",
    "50,199 SPAM\n",
    "\n",
    "These messages contitute all the messages delivered to a particular serever between these dates:\n",
    "\n",
    "Sun, 8 Apr 2007 13:07:21 -0400\n",
    "Fri, 6 Jul 2007 07:04:53 -0400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fd5ed",
   "metadata": {},
   "source": [
    "### 1.- Funciones complementarias \n",
    "\n",
    "En este caso práctico relacionado con la detección de e-mails de SPAM, el DataSet del que se dispone, esta formado por e-mails, con sus correspondientes cabeceras y campos adicionales. Por lo tanto, requieren un preprocesamiento previo a ser ingeridos por el algoritmo Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc7cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta clase facilita el preprocesamiento de correos electrónicos que poseen codigo HTML\n",
    "from html.parser import HTMLParser\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60911099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función se encarga de eliminar los tags HTML que se encuentran en el texto del e-mail\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0748ad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrack World News'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Ejemplo de eliminación de los tags HTML de un texto\n",
    "t = '<tr><td align=\"left\"><a href=\"../../issues/51/16.html#article\">Phrack World News</a></td>'\n",
    "strip_tags(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310592f",
   "metadata": {},
   "source": [
    "Ademas de eliminar los posibles tags HTML que se encuentren en el coreo electrónico, deben realizarse otras acciones de preprocesamiento para evitar que los mensajes tengan ruido inecesario. Entre ellas se encuentra la eliminación de los signos de puntuación, eliminación de posibles campos de correo electrónico que no son reelevantes o eliminación de afijos de una palabra manteniendo únicamente la raiz de la misma (Stemming), La clase que se muestra a continuación realiza estas transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6896397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626b120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer =  nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self.punctuation = list(string.punctuation)\n",
    "\n",
    "\n",
    "    def parse(self, email_path):\n",
    "        \"\"\"Parse an email\"\"\"\n",
    "        with open(email_path, errors='ignore') as e:\n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg)  \n",
    "        \n",
    "    def get_email_content(self, msg):\n",
    "        \"\"\"Extract the email content\"\"\"\n",
    "        subject = self.tokenize(msg['Subject']) if msg['Subject'] else[]\n",
    "        body = self.get_email_body(msg.get_payload(),\n",
    "                                   msg.get_content_type())\n",
    "        content_type = msg.get_content_type()\n",
    "        # Returning the content of the email\n",
    "        return {\"subject\": subject,\n",
    "                \"body\": body,\n",
    "                \"content_type\": content_type}\n",
    "    \n",
    "    def get_email_body(self, payload, content_type):\n",
    "        \"\"\"Extract the body of the email\"\"\"\n",
    "        body = []\n",
    "        if type(payload) is str and content_type == 'text/plain':\n",
    "            return self.tokenize(payload)\n",
    "        elif type(payload) is str and content_type == 'text/html':\n",
    "            return self.tokenize(strip_tags(payload))\n",
    "        elif type(payload) is list:\n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(),\n",
    "                                   p.get_content_type())\n",
    "        return body\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Transform a text string in tokens, perform two main action \n",
    "        clean the puntuation symbols and do stemming of the text\"\"\"\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\"\")))\n",
    "        #Stemming of the tokens\n",
    "        return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e935f",
   "metadata": {},
   "source": [
    "Lectura de un e-mail en formato Raw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cedaa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From RickyAmes@aol.com  Sun Apr  8 13:07:32 2007\n",
      "Return-Path: <RickyAmes@aol.com>\n",
      "Received: from 129.97.78.23 ([211.202.101.74])\n",
      "\tby speedy.uwaterloo.ca (8.12.8/8.12.5) with SMTP id l38H7G0I003017;\n",
      "\tSun, 8 Apr 2007 13:07:21 -0400\n",
      "Received: from 0.144.152.6 by 211.202.101.74; Sun, 08 Apr 2007 19:04:48 +0100\n",
      "Message-ID: <WYADCKPDFWWTWTXNFVUE@yahoo.com>\n",
      "From: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
      "Reply-To: \"Tomas Jacobs\" <RickyAmes@aol.com>\n",
      "To: the00@speedy.uwaterloo.ca\n",
      "Subject: Generic Cialis, branded quality@ \n",
      "Date: Sun, 08 Apr 2007 21:00:48 +0300\n",
      "X-Mailer: Microsoft Outlook Express 6.00.2600.0000\n",
      "MIME-Version: 1.0\n",
      "Content-Type: multipart/alternative;\n",
      "\tboundary=\"--8896484051606557286\"\n",
      "X-Priority: 3\n",
      "X-MSMail-Priority: Normal\n",
      "Status: RO\n",
      "Content-Length: 988\n",
      "Lines: 24\n",
      "\n",
      "----8896484051606557286\n",
      "Content-Type: text/html;\n",
      "Content-Transfer-Encoding: 7Bit\n",
      "\n",
      "<html>\n",
      "<body bgcolor=\"#ffffff\">\n",
      "<div style=\"border-color: #00FFFF; border-right-width: 0px; border-bottom-width: 0px; margin-bottom: 0px;\" align=\"center\">\n",
      "<table style=\"border: 1px; border-style: solid; border-color:#000000;\" cellpadding=\"5\" cellspacing=\"0\" bgcolor=\"#CCFFAA\">\n",
      "<tr>\n",
      "<td style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
      "<center>\n",
      "Do you feel the pressure to perform and not rising to the occasion??<br>\n",
      "</center>\n",
      "</td></tr><tr>\n",
      "<td bgcolor=#FFFF33 style=\"border: 0px; border-bottom: 1px; border-style: solid; border-color:#000000;\">\n",
      "<center>\n",
      "\n",
      "<b><a href='http://excoriationtuh.com/?lzmfnrdkleks'>Try <span>V</span><span>ia<span></span>gr<span>a</span>.....</a></b></center>\n",
      "</td></tr><td><center>your anxiety will be a thing of the past and you will<br>\n",
      "be back to your old self.\n",
      "</center></td></tr></table></div></body></html>\n",
      "\n",
      "\n",
      "----8896484051606557286--\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inmail = open(\"/home/hernan_so5/Documentos/Ejercicios_jupyter/datasets/datasets/trec07p/data/inmail.1\").read()\n",
    "print(inmail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa6b11",
   "metadata": {},
   "source": [
    "Parsear el e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dceab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hernan_so5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mstopwords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m p = Parser()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/hernan_so5/Documentos/Ejercicios_jupyter/datasets/datasets/trec07p/data/inmail.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self, email_path)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(email_path, errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     12\u001b[39m     msg = email.message_from_file(e)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m msg \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_email_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mParser.get_email_content\u001b[39m\u001b[34m(self, msg)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_email_content\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Extract the email content\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     subject = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSubject\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m msg[\u001b[33m'\u001b[39m\u001b[33mSubject\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m[]\n\u001b[32m     18\u001b[39m     body = \u001b[38;5;28mself\u001b[39m.get_email_body(msg.get_payload(),\n\u001b[32m     19\u001b[39m                                msg.get_content_type())\n\u001b[32m     20\u001b[39m     content_type = msg.get_content_type()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mParser.tokenize\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     44\u001b[39m text = text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m text = text.replace(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m tokens = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m#Stemming of the tokens\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.stemmer.stem(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stopwords]\n",
      "\u001b[31mValueError\u001b[39m: empty separator"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "p = Parser()\n",
    "p.parse(\"/home/hernan_so5/Documentos/Ejercicios_jupyter/datasets/datasets/trec07p/data/inmail.1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
